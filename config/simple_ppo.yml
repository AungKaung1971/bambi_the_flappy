type: simple
hyperparameters:
  algorithm: PPO
  policy: MlpPolicy
  learning_rate: 0.0001
  gamma: 0.99
  n_steps: 4096
  batch_size: 256
  ent_coef: 0.01

total_timesteps: 500000
eval_freq: 10000

checkpoints:
  prefix: flappy_ppo

reward:
  survival: 1
  pipe: 10
  death: -100
